{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca97813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b930c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d4ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the training dataset\n",
    "dataset_train = pd.read_csv('D:/Users/dell1/Desktop/CERTIFICATES/Deep learning/RNN/Part+3+-+Recurrent+Neural+Networks/Part 3 - Recurrent Neural Networks/Google_Stock_Price_Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a982e209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Open    High     Low   Close      Volume\n",
       "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the first 5 rows\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3508f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date      0\n",
       "Open      0\n",
       "High      0\n",
       "Low       0\n",
       "Close     0\n",
       "Volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the null values\n",
    "dataset_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5d1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the data to array\n",
    "train_set = dataset_train.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec10c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "train_set = sc.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb53134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a data structure with 120 timesteps and 1 output\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(120,1258):\n",
    "    x_train.append(train_set[i-120:i,0])\n",
    "    y_train.append(train_set[i,0])\n",
    "    \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "951aa554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping x_train\n",
    "x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e52e45",
   "metadata": {},
   "source": [
    "# Building the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "178d8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the RNN\n",
    "regressor = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b4208a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the 1st LSTM layer and dropout regularisation\n",
    "regressor.add(tf.keras.layers.LSTM(units = 100,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dc15289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the 2nd LSTM layer and dropout regularisation\n",
    "regressor.add(tf.keras.layers.LSTM(units = 100,return_sequences = True))\n",
    "regressor.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47bb871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the 3rd LSTM layer and dropout regularisation\n",
    "regressor.add(tf.keras.layers.LSTM(units = 100,return_sequences = True))\n",
    "regressor.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76906756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the 4th LSTM layer and dropout regularisation\n",
    "regressor.add(tf.keras.layers.LSTM(units = 100,return_sequences = True))\n",
    "regressor.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bf23137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the output layer\n",
    "regressor.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d89f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the RNN\n",
    "regressor.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d52d374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 24s 428ms/step - loss: 0.1003\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0734\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 15s 415ms/step - loss: 0.0733\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 15s 408ms/step - loss: 0.0721\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 13s 362ms/step - loss: 0.0710\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0702\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 16s 435ms/step - loss: 0.0714\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 16s 448ms/step - loss: 0.0707\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 12s 345ms/step - loss: 0.0703\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 17s 475ms/step - loss: 0.0705\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 19s 532ms/step - loss: 0.0694\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 20s 544ms/step - loss: 0.0689\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 19s 534ms/step - loss: 0.0690\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 20s 547ms/step - loss: 0.0689\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 19s 526ms/step - loss: 0.0684\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 19s 534ms/step - loss: 0.0684\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 19s 530ms/step - loss: 0.0684\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 18s 507ms/step - loss: 0.0682\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 19s 515ms/step - loss: 0.0681\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 19s 541ms/step - loss: 0.0686\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 20s 558ms/step - loss: 0.0690\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 19s 515ms/step - loss: 0.0681\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 20s 545ms/step - loss: 0.0688\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 18s 513ms/step - loss: 0.0681\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0679\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 15s 403ms/step - loss: 0.0678\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 14s 396ms/step - loss: 0.0682\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 15s 413ms/step - loss: 0.0678\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 15s 414ms/step - loss: 0.0681\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 15s 403ms/step - loss: 0.0680\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 14s 391ms/step - loss: 0.0676\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 15s 417ms/step - loss: 0.0678\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 15s 404ms/step - loss: 0.0686\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 15s 410ms/step - loss: 0.0681\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 14s 399ms/step - loss: 0.0681\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 14s 386ms/step - loss: 0.0672\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 14s 393ms/step - loss: 0.0678\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 15s 405ms/step - loss: 0.0674\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 15s 406ms/step - loss: 0.0677\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 14s 398ms/step - loss: 0.0680\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 14s 391ms/step - loss: 0.0677\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 15s 410ms/step - loss: 0.0684\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0680\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 15s 411ms/step - loss: 0.0675\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 15s 419ms/step - loss: 0.0674\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0675\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 14s 395ms/step - loss: 0.0673\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 14s 386ms/step - loss: 0.0673\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 14s 399ms/step - loss: 0.0677\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 14s 397ms/step - loss: 0.0674\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 15s 412ms/step - loss: 0.0674\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 14s 400ms/step - loss: 0.0674\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 14s 397ms/step - loss: 0.0675\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 15s 412ms/step - loss: 0.0673\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 15s 413ms/step - loss: 0.0675\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 15s 409ms/step - loss: 0.0677\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 15s 411ms/step - loss: 0.0674\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 15s 410ms/step - loss: 0.0674\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 14s 399ms/step - loss: 0.0677\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 15s 409ms/step - loss: 0.0674\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 15s 404ms/step - loss: 0.0673\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 14s 384ms/step - loss: 0.0672\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0673\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 17s 467ms/step - loss: 0.0676\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 19s 525ms/step - loss: 0.0674\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 16s 452ms/step - loss: 0.0673\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 14s 397ms/step - loss: 0.0681\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 15s 414ms/step - loss: 0.0672\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 16s 436ms/step - loss: 0.0671\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 15s 415ms/step - loss: 0.0677\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 18s 491ms/step - loss: 0.0673\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 45s 1s/step - loss: 0.0673\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 21s 558ms/step - loss: 0.0671\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 14s 379ms/step - loss: 0.0678\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 14s 389ms/step - loss: 0.0675\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 0.0672\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 13s 369ms/step - loss: 0.0675\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 0.0673\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 0.0673\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 13s 374ms/step - loss: 0.0675\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 0.0678\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 14s 385ms/step - loss: 0.0672\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 14s 387ms/step - loss: 0.0673\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 13s 365ms/step - loss: 0.0672\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 14s 379ms/step - loss: 0.0673\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 14s 379ms/step - loss: 0.0674\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 14s 378ms/step - loss: 0.0672\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 17s 472ms/step - loss: 0.0672\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 0.0672\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 14s 382ms/step - loss: 0.0672\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 14s 396ms/step - loss: 0.0675\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 14s 375ms/step - loss: 0.0671\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 13s 372ms/step - loss: 0.0674\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 14s 377ms/step - loss: 0.0674\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 14s 374ms/step - loss: 0.0671\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 13s 374ms/step - loss: 0.0675\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 14s 380ms/step - loss: 0.0671\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 13s 372ms/step - loss: 0.0670\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 13s 372ms/step - loss: 0.0676\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 13s 374ms/step - loss: 0.0675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x191d53bb580>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the RNN into the training set\n",
    "regressor.fit(x_train,y_train,epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97e421",
   "metadata": {},
   "source": [
    "# Making the prediction and Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "367025c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the testing data\n",
    "dataset_test = pd.read_csv('D:/Users/dell1/Desktop/CERTIFICATES/Deep learning/RNN/Part+3+-+Recurrent+Neural+Networks/Part 3 - Recurrent Neural Networks/Google_Stock_Price_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b2494cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = dataset_test.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "660c3682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.52025104],\n",
       "        [0.49902317],\n",
       "        [0.50479245],\n",
       "        ...,\n",
       "        [0.5064489 ],\n",
       "        [0.5064255 ],\n",
       "        [0.50638914]],\n",
       "\n",
       "       [[0.52023864],\n",
       "        [0.49903193],\n",
       "        [0.5047915 ],\n",
       "        ...,\n",
       "        [0.5064255 ],\n",
       "        [0.50638914],\n",
       "        [0.5063393 ]],\n",
       "\n",
       "       [[0.5202639 ],\n",
       "        [0.49904004],\n",
       "        [0.5048284 ],\n",
       "        ...,\n",
       "        [0.50638914],\n",
       "        [0.5063393 ],\n",
       "        [0.50632954]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.52055633],\n",
       "        [0.4995796 ],\n",
       "        [0.50562274],\n",
       "        ...,\n",
       "        [0.5069033 ],\n",
       "        [0.5070162 ],\n",
       "        [0.5071554 ]],\n",
       "\n",
       "       [[0.52060616],\n",
       "        [0.49961928],\n",
       "        [0.5056696 ],\n",
       "        ...,\n",
       "        [0.5070162 ],\n",
       "        [0.5071554 ],\n",
       "        [0.50726974]],\n",
       "\n",
       "       [[0.5206007 ],\n",
       "        [0.49962687],\n",
       "        [0.5056852 ],\n",
       "        ...,\n",
       "        [0.5071554 ],\n",
       "        [0.50726974],\n",
       "        [0.5072811 ]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e48d6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the predicted stock price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis=0)\n",
    "inputs = dataset_total[len(dataset_total)-len(dataset_test)-120:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "x_test = []\n",
    "for i in range(120,140):\n",
    "    x_test.append(inputs[i-120:i,0])\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d21e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping x-test\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98800a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the prediction\n",
    "predicted_stock_price = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5115f38f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-eaa6291c31da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Inverse scalig the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredicted_stock_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_stock_price\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m         X = check_array(\n\u001b[0m\u001b[0;32m    538\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m             )\n\u001b[0;32m    914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    916\u001b[0m                 \u001b[1;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m                 \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "#Inverse scalig the output\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f8fb06d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2-D, but have shapes (20,) and (20, 120, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-627ee460a49a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Real google stock price'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_stock_price\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Predicted google stock price'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Google Stock Price Prediction'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2838\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2839\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2840\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2841\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2842\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             raise ValueError(f\"x and y can be no greater than 2-D, but have \"\n\u001b[0m\u001b[0;32m    403\u001b[0m                              f\"shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y can be no greater than 2-D, but have shapes (20,) and (20, 120, 1)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing the performance through graph\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(test_set, color ='r', label = 'Real google stock price')\n",
    "plt.plot(predicted_stock_price, color = 'b', label = 'Predicted google stock price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google stock price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7868f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "regressor.save('regressor.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "000c60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "loaded_model = tf.keras.models.load_model('regressor.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87899df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the scaled model\n",
    "import pickle\n",
    "filename = 'trained_model_scaled.sav'\n",
    "pickle.dump(sc,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "576b0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the scaled model\n",
    "loaded_model_scaled = pickle.load(open('trained_model_scaled.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b1a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaledata(data):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    data_target_scaled = scaler.fit_transform(np.array(data).reshape(-1,1))\n",
    "    #plot_scaled = pd.DataFrame(data_target_scaled).plot()\n",
    "    print(data.shape)\n",
    "    return data_target_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "702c69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def futurePrediciton1D(curr_data,start=\"2021-02-1\",end=\"2021-06-19\"):\n",
    "    '''\n",
    "    '''\n",
    "    x_data = curr_data[len(curr_data)-120:]\n",
    "    curr_scaled = scaledata(x_data)[0]\n",
    "    scaler = scaledata(curr_data)[1]\n",
    "    \n",
    "    #flatten into list\n",
    "    x_data = list(curr_scaled.flatten())\n",
    "    #convert into 3D\n",
    "    x_data = np.array(x_data)\n",
    "    x_data = x_data.reshape(1,len(x_data),1)\n",
    "    #x_data = x_data[len(x_data)-120:]\n",
    "    #x_data = tf.expand_dims(x_data,axis=1)\n",
    "    \n",
    "    #Predict\n",
    "    nextDay = loaded_model.predict(x=x_data)\n",
    "    nextDay = scaler.inverse_transform(nextDay.reshape(-1,1))\n",
    "\n",
    "    nextDay = nextDay[-1][0]\n",
    "    print(\"Prediction: {}\".format(nextDay))\n",
    "    \n",
    "    #convert into dataframe again\n",
    "    curr_data = pd.DataFrame(curr_data)\n",
    "    curr_data.reset_index(inplace=True)\n",
    "    open_cl = curr_data[['Open']]\n",
    "    \n",
    "    #concatenate new value\n",
    "    open_cl.loc[len(open_cl.index)] = [nextDay]\n",
    "    \n",
    "    return open_cl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88170166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the training dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "dataset_train = pd.read_csv('D:/Users/dell1/Desktop/CERTIFICATES/Deep learning/RNN/Part+3+-+Recurrent+Neural+Networks/Part 3 - Recurrent Neural Networks/Google_Stock_Price_Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80b889da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>12/23/2016</td>\n",
       "      <td>790.90</td>\n",
       "      <td>792.74</td>\n",
       "      <td>787.28</td>\n",
       "      <td>789.91</td>\n",
       "      <td>623,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>12/27/2016</td>\n",
       "      <td>790.68</td>\n",
       "      <td>797.86</td>\n",
       "      <td>787.66</td>\n",
       "      <td>791.55</td>\n",
       "      <td>789,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>12/28/2016</td>\n",
       "      <td>793.70</td>\n",
       "      <td>794.23</td>\n",
       "      <td>783.20</td>\n",
       "      <td>785.05</td>\n",
       "      <td>1,153,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>12/29/2016</td>\n",
       "      <td>783.33</td>\n",
       "      <td>785.93</td>\n",
       "      <td>778.92</td>\n",
       "      <td>782.79</td>\n",
       "      <td>744,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>12/30/2016</td>\n",
       "      <td>782.75</td>\n",
       "      <td>782.78</td>\n",
       "      <td>770.41</td>\n",
       "      <td>771.82</td>\n",
       "      <td>1,770,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close     Volume\n",
       "1253  12/23/2016  790.90  792.74  787.28  789.91    623,400\n",
       "1254  12/27/2016  790.68  797.86  787.66  791.55    789,100\n",
       "1255  12/28/2016  793.70  794.23  783.20  785.05  1,153,800\n",
       "1256  12/29/2016  783.33  785.93  778.92  782.79    744,300\n",
       "1257  12/30/2016  782.75  782.78  770.41  771.82  1,770,000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = dataset_train.iloc[:,1:2].values\n",
    "dataset_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fe1d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120,)\n",
      "(1258,)\n",
      "Prediction: 642.11474609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell1\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>331.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>328.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>322.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>790.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>793.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>783.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>782.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>642.114746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open\n",
       "0     325.250000\n",
       "1     331.270000\n",
       "2     329.830000\n",
       "3     328.340000\n",
       "4     322.040000\n",
       "...          ...\n",
       "1254  790.680000\n",
       "1255  793.700000\n",
       "1256  783.330000\n",
       "1257  782.750000\n",
       "1258  642.114746\n",
       "\n",
       "[1259 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futurePrediciton1D(dataset_train['Open'],start='2012-03-01', end='2017-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "343aaaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       325.25\n",
       "1       331.27\n",
       "2       329.83\n",
       "3       328.34\n",
       "4       322.04\n",
       "         ...  \n",
       "1253    790.90\n",
       "1254    790.68\n",
       "1255    793.70\n",
       "1256    783.33\n",
       "1257    782.75\n",
       "Name: Open, Length: 1258, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a29b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('regressor.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dd640b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08581368],\n",
       "       [0.09701243],\n",
       "       [0.09433366],\n",
       "       ...,\n",
       "       [0.95725128],\n",
       "       [0.93796041],\n",
       "       [0.93688146]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledata(dataset_train['Open'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68f09ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258,)\n",
      "(1258,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08581368],\n",
       "       [0.09701243],\n",
       "       [0.09433366],\n",
       "       ...,\n",
       "       [0.95725128],\n",
       "       [0.93796041],\n",
       "       [0.93688146]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_target_scaled = scaledata(dataset_train['Open'])[0]\n",
    "scaler = scaledata(dataset_train['Open'])[1]\n",
    "data_target_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8abf4ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>12/23/2016</td>\n",
       "      <td>790.90</td>\n",
       "      <td>792.74</td>\n",
       "      <td>787.28</td>\n",
       "      <td>789.91</td>\n",
       "      <td>623,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>12/27/2016</td>\n",
       "      <td>790.68</td>\n",
       "      <td>797.86</td>\n",
       "      <td>787.66</td>\n",
       "      <td>791.55</td>\n",
       "      <td>789,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>12/28/2016</td>\n",
       "      <td>793.70</td>\n",
       "      <td>794.23</td>\n",
       "      <td>783.20</td>\n",
       "      <td>785.05</td>\n",
       "      <td>1,153,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>12/29/2016</td>\n",
       "      <td>783.33</td>\n",
       "      <td>785.93</td>\n",
       "      <td>778.92</td>\n",
       "      <td>782.79</td>\n",
       "      <td>744,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>12/30/2016</td>\n",
       "      <td>782.75</td>\n",
       "      <td>782.78</td>\n",
       "      <td>770.41</td>\n",
       "      <td>771.82</td>\n",
       "      <td>1,770,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close      Volume\n",
       "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
       "...          ...     ...     ...     ...     ...         ...\n",
       "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
       "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
       "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
       "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
       "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b261b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('D:/Users/dell1/Downloads/GOOG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1bc1588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120,)\n",
      "(250,)\n",
      "Prediction: 119.86969757080078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell1\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.514503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.092003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.008003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118.650002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>117.839996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>117.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>120.089996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>121.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>119.869698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open\n",
       "0    107.514503\n",
       "1    114.092003\n",
       "2    116.008003\n",
       "3    117.550003\n",
       "4    118.650002\n",
       "..          ...\n",
       "246  117.839996\n",
       "247  117.959999\n",
       "248  120.089996\n",
       "249  121.099998\n",
       "250  119.869698\n",
       "\n",
       "[251 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futurePrediciton1D(d['Open'],start='2012-03-01', end='2017-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fc07c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-05</td>\n",
       "      <td>107.514503</td>\n",
       "      <td>114.052597</td>\n",
       "      <td>106.249496</td>\n",
       "      <td>113.887001</td>\n",
       "      <td>113.887001</td>\n",
       "      <td>36398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>114.092003</td>\n",
       "      <td>116.351997</td>\n",
       "      <td>112.250504</td>\n",
       "      <td>115.213501</td>\n",
       "      <td>115.213501</td>\n",
       "      <td>28852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>116.008003</td>\n",
       "      <td>119.862000</td>\n",
       "      <td>115.533997</td>\n",
       "      <td>119.306000</td>\n",
       "      <td>119.306000</td>\n",
       "      <td>32184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-08</td>\n",
       "      <td>117.550003</td>\n",
       "      <td>120.434998</td>\n",
       "      <td>117.514000</td>\n",
       "      <td>120.168503</td>\n",
       "      <td>120.168503</td>\n",
       "      <td>29082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-11</td>\n",
       "      <td>118.650002</td>\n",
       "      <td>118.794502</td>\n",
       "      <td>116.234497</td>\n",
       "      <td>116.522499</td>\n",
       "      <td>116.522499</td>\n",
       "      <td>26718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2023-06-26</td>\n",
       "      <td>121.466003</td>\n",
       "      <td>122.720001</td>\n",
       "      <td>118.989998</td>\n",
       "      <td>119.089996</td>\n",
       "      <td>119.089996</td>\n",
       "      <td>23185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2023-06-27</td>\n",
       "      <td>117.839996</td>\n",
       "      <td>119.894997</td>\n",
       "      <td>116.910004</td>\n",
       "      <td>119.010002</td>\n",
       "      <td>119.010002</td>\n",
       "      <td>27221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>117.959999</td>\n",
       "      <td>121.269997</td>\n",
       "      <td>117.599998</td>\n",
       "      <td>121.080002</td>\n",
       "      <td>121.080002</td>\n",
       "      <td>19753100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>120.089996</td>\n",
       "      <td>120.910004</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>120.010002</td>\n",
       "      <td>120.010002</td>\n",
       "      <td>18517500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>121.099998</td>\n",
       "      <td>122.029999</td>\n",
       "      <td>120.879997</td>\n",
       "      <td>120.970001</td>\n",
       "      <td>120.970001</td>\n",
       "      <td>23865800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2022-07-05  107.514503  114.052597  106.249496  113.887001  113.887001   \n",
       "1    2022-07-06  114.092003  116.351997  112.250504  115.213501  115.213501   \n",
       "2    2022-07-07  116.008003  119.862000  115.533997  119.306000  119.306000   \n",
       "3    2022-07-08  117.550003  120.434998  117.514000  120.168503  120.168503   \n",
       "4    2022-07-11  118.650002  118.794502  116.234497  116.522499  116.522499   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "245  2023-06-26  121.466003  122.720001  118.989998  119.089996  119.089996   \n",
       "246  2023-06-27  117.839996  119.894997  116.910004  119.010002  119.010002   \n",
       "247  2023-06-28  117.959999  121.269997  117.599998  121.080002  121.080002   \n",
       "248  2023-06-29  120.089996  120.910004  119.209999  120.010002  120.010002   \n",
       "249  2023-06-30  121.099998  122.029999  120.879997  120.970001  120.970001   \n",
       "\n",
       "       Volume  \n",
       "0    36398000  \n",
       "1    28852000  \n",
       "2    32184000  \n",
       "3    29082000  \n",
       "4    26718000  \n",
       "..        ...  \n",
       "245  23185000  \n",
       "246  27221700  \n",
       "247  19753100  \n",
       "248  18517500  \n",
       "249  23865800  \n",
       "\n",
       "[250 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36517e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
